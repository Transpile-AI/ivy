{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%cd .."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "API_KEY = \"\"\n",
    "!mkdir -p .ivy\n",
    "!echo -n $API_KEY > .ivy/key.pem\n",
    "%cd .."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import jax\n",
    "import haiku as hk\n",
    "import ivy\n",
    "import torch\n",
    "import requests\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import traceback\n",
    "\n",
    "import torchvision\n",
    "from mmpretrain import get_model, list_models, inference_model\n",
    "from mmengine import ConfigDict\n",
    "\n",
    "jax.config.update(\"jax_enable_x64\", True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_scale(cfg):\n",
    "  if type(cfg) == ConfigDict:\n",
    "    if cfg.get('type', False) and cfg.get('scale', False):\n",
    "      return cfg['scale']\n",
    "    else:\n",
    "      for k in cfg.keys():\n",
    "        input_shape = get_scale(cfg[k])\n",
    "        if input_shape:\n",
    "          return input_shape\n",
    "  elif type(cfg) == list:\n",
    "    for block in cfg:\n",
    "      input_shape = get_scale(block)\n",
    "      if input_shape:\n",
    "        return input_shape\n",
    "  else:\n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tested_model_archs = []\n",
    "def to_test(model_name):\n",
    "    if '-base' in model_name:\n",
    "        short = model_name.split(\"-base\")[0]\n",
    "        if short in tested_model_archs:\n",
    "            return False\n",
    "        else:\n",
    "            tested_model_archs.append(short)\n",
    "            return True\n",
    "    short = model_name.split(\"-\")[0]\n",
    "    if short in tested_model_archs:\n",
    "        return False\n",
    "    else:\n",
    "        tested_model_archs.append(short)\n",
    "        return True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_from = 35\n",
    "for i, model_name in enumerate(list_models()[start_from:]):\n",
    "  print(f'testing {model_name} -> {i+start_from}')\n",
    "  if not to_test(model_name):\n",
    "    print('skipped because this arch already tested before')\n",
    "    continue\n",
    "  try:\n",
    "    model = get_model(model_name, pretrained=True)\n",
    "  except Exception as e:\n",
    "    print(f'model was skipped due to {traceback.format_exc()}')\n",
    "    continue\n",
    "  input_shape = get_scale(model._config.train_pipeline)\n",
    "  assert type(input_shape) == int, 'input shape was not detected'\n",
    "  url = \"http://images.cocodataset.org/val2017/000000039769.jpg\"\n",
    "  image = Image.open(requests.get(url, stream=True).raw)\n",
    "  transform = torchvision.transforms.Compose([\n",
    "      torchvision.transforms.Resize((input_shape, input_shape)),\n",
    "      torchvision.transforms.ToTensor()\n",
    "  ])\n",
    "  tensor_image = transform(image).unsqueeze(0)\n",
    "  print('transpiling..')\n",
    "  transpiled_graph = ivy.transpile(model, to=\"haiku\", args=(tensor_image,))\n",
    "\n",
    "  tensor_image = transform(image).unsqueeze(0)\n",
    "\n",
    "  def _f(args):\n",
    "    return model(args)\n",
    "\n",
    "  comp_model = torch.compile(_f)\n",
    "  _ = comp_model(tensor_image)\n",
    "\n",
    "  tensor_image = transform(image).unsqueeze(0)\n",
    "  np_image = tensor_image.detach().cpu().numpy()\n",
    "\n",
    "  def _forward(args):\n",
    "    module = transpiled_graph()\n",
    "    return module(args)\n",
    "\n",
    "  _forward = jax.jit(_forward)\n",
    "  rng_key = jax.random.PRNGKey(42)\n",
    "  jax_mlp_forward = hk.transform(_forward)\n",
    "  params = jax_mlp_forward.init(rng=rng_key, args=np_image)\n",
    "\n",
    "  url = \"http://images.cocodataset.org/train2017/000000283921.jpg\"\n",
    "  image = Image.open(requests.get(url, stream=True).raw)\n",
    "  tensor_image = transform(image).unsqueeze(0)\n",
    "  np_image = tensor_image.detach().cpu().numpy()\n",
    "  out_torch = comp_model(tensor_image)\n",
    "  out_jax = jax_mlp_forward.apply(params, None, np_image)\n",
    "\n",
    "  if type(out_torch) == torch.Tensor:\n",
    "    print(np.allclose(out_torch.detach().cpu().numpy(), out_jax, atol=1e-3))\n",
    "  else:\n",
    "    print('Fancy output detected. Vverify manually depending on output structure')\n",
    "  del model, transpiled_graph, comp_model, params, jax_mlp_forward\n",
    "  del tensor_image, np_image\n",
    "  del out_torch, out_jax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
